"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[61419],{28453(e,n,s){s.d(n,{R:()=>r,x:()=>a});var i=s(96540);const t={},l=i.createContext(t);function r(e){const n=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(l.Provider,{value:n},e.children)}},62747(e,n,s){s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>f,frontMatter:()=>r,metadata:()=>i,toc:()=>p});const i=JSON.parse('{"id":"Computer/Application/Obsidian/Obsidian Web Clipper","title":"Obsidian Web Clipper","description":"\u754c\u9762","source":"@site/vault/Areas/Computer/90_Application/Obsidian/Obsidian Web Clipper.md","sourceDirName":"Computer/90_Application/Obsidian","slug":"/Computer/Application/Obsidian/Obsidian Web Clipper","permalink":"/docs/Computer/Application/Obsidian/Obsidian Web Clipper","draft":false,"unlisted":true,"tags":[],"version":"current","lastUpdatedAt":1770039016000,"frontMatter":{"modified":"2025-12-02T22:05","unlisted":true,"url":["https://obsidian.md/clipper","https://help.obsidian.md/web-clipper"],"aliases":["Obsidian \u526a\u85cf"],"date":"2025-12-02T22:03"},"sidebar":"obsidianSidebar"}');var t=s(74848),l=s(28453);const r={modified:"2025-12-02T22:05",unlisted:!0,url:["https://obsidian.md/clipper","https://help.obsidian.md/web-clipper"],aliases:["Obsidian \u526a\u85cf"],date:"2025-12-02T22:03"},a=void 0,o={},p=[{value:"\u754c\u9762",id:"\u754c\u9762",level:2},{value:"\u8bbe\u7f6e",id:"\u8bbe\u7f6e",level:2},{value:"\u6a21\u677f",id:"\u6a21\u677f",level:2},{value:"\u53d8\u91cf",id:"\u53d8\u91cf",level:2},{value:"\u8fc7\u6ee4\u5668",id:"\u8fc7\u6ee4\u5668",level:2},{value:"Examples",id:"examples",level:2},{value:"\u811a\u672c",id:"\u811a\u672c",level:2}];function d(e){const n={code:"code",h2:"h2",li:"li",pre:"pre",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"\u754c\u9762",children:"\u754c\u9762"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Header","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u6a21\u677f"}),"\n",(0,t.jsx)(n.li,{children:"\u663e\u793a\u9875\u9762\u53d8\u91cf"}),"\n",(0,t.jsx)(n.li,{children:"\u9ad8\u4eae"}),"\n",(0,t.jsx)(n.li,{children:"\u5728\u9875\u9762\u4e2d\u6253\u5f00"}),"\n",(0,t.jsx)(n.li,{children:"\u8bbe\u7f6e"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"Properties"}),"\n",(0,t.jsx)(n.li,{children:"Note content"}),"\n",(0,t.jsxs)(n.li,{children:["Footer","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u6dfb\u52a0"}),"\n",(0,t.jsx)(n.li,{children:"\u6587\u4ef6\u5939"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"\u8bbe\u7f6e",children:"\u8bbe\u7f6e"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u5e38\u89c4"}),"\n",(0,t.jsx)(n.li,{children:"\u5c5e\u6027"}),"\n",(0,t.jsx)(n.li,{children:"\u9ad8\u4eae"}),"\n",(0,t.jsx)(n.li,{children:"\u89e3\u91ca\u5668"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"\u6a21\u677f",children:"\u6a21\u677f"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u540d\u79f0"}),"\n",(0,t.jsx)(n.li,{children:"\u884c\u4e3a"}),"\n",(0,t.jsx)(n.li,{children:"\u6587\u4ef6\u540d"}),"\n",(0,t.jsx)(n.li,{children:"\u6587\u4ef6\u5939"}),"\n",(0,t.jsx)(n.li,{children:"\u5e93"}),"\n",(0,t.jsx)(n.li,{children:"\u89e6\u53d1\u5668"}),"\n",(0,t.jsx)(n.li,{children:"\u5c5e\u6027"}),"\n",(0,t.jsx)(n.li,{children:"\u5185\u5bb9"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"\u53d8\u91cf",children:"\u53d8\u91cf"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Preset variables"}),"\n",(0,t.jsx)(n.li,{children:"Prompt variables"}),"\n",(0,t.jsx)(n.li,{children:"Meta variables"}),"\n",(0,t.jsx)(n.li,{children:"Selector variables"}),"\n",(0,t.jsx)(n.li,{children:"Schema.org variables"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"\u8fc7\u6ee4\u5668",children:"\u8fc7\u6ee4\u5668"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Dates"}),"\n",(0,t.jsx)(n.li,{children:"Text conversion and capitalization"}),"\n",(0,t.jsx)(n.li,{children:"Text formatting"}),"\n",(0,t.jsx)(n.li,{children:"Numbers"}),"\n",(0,t.jsx)(n.li,{children:"HTML processing"}),"\n",(0,t.jsx)(n.li,{children:"Arrays and objects"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",metastring:"fold",children:'{\n  "schemaVersion": "0.1.0",\n  "name": "91",\n  "behavior": "create",\n  "noteContentFormat": "\\n{{selector:video?poster|image}}\\n",\n  "properties": [\n    {\n      "name": "title",\n      "value": "{{title}}",\n      "type": "text"\n    },\n    {\n      "name": "url",\n      "value": "{{url}}",\n      "type": "text"\n    },\n    {\n      "name": "image",\n      "value": "{{image}}",\n      "type": "text"\n    },\n    {\n      "name": "tags",\n      "value": "clippings/91, av",\n      "type": "multitext"\n    },\n    {\n      "name": "created",\n      "value": "{{time}} ",\n      "type": "date"\n    }\n  ],\n  "triggers": [\n    "/^https:\\\\/\\\\/(.*)\\\\/video(s)?\\\\/view(hd)?\\\\/(.*)/"\n  ],\n  "noteNameFormat": "{{title|safe_name}}",\n  "path": "Inbox"\n}\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",metastring:"fold",children:'{\n  "schemaVersion": "0.1.0",\n  "name": "51",\n  "behavior": "create",\n  "noteContentFormat": "\\n{{selector:div.post-content img:is([src^=\\"data:image/jpeg;base64,\\"], [src^=\\"data:image/jpg;base64,\\"])?src|slice:0,-1|image|join:\\"\\\\n\\\\n\\"}}\\n",\n  "properties": [\n    {\n      "name": "title",\n      "value": "{{title}}",\n      "type": "text"\n    },\n    {\n      "name": "url",\n      "value": "{{url}}",\n      "type": "text"\n    },\n    {\n      "name": "image",\n      "value": "",\n      "type": "text"\n    },\n    {\n      "name": "tags",\n      "value": "clippings/51, av",\n      "type": "multitext"\n    },\n    {\n      "name": "created",\n      "value": "{{time}} ",\n      "type": "date"\n    }\n  ],\n  "triggers": [\n    "/https:\\\\/\\\\/(.*)\\\\/archives\\\\/(\\\\d+)/"\n  ],\n  "noteNameFormat": "{{title|safe_name}}",\n  "path": "Inbox"\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"\u811a\u672c",children:"\u811a\u672c"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:"fold",children:"import base64\nfrom datetime import datetime\nimport hashlib\nimport os\nimport re\nimport traceback\nfrom urllib.parse import urlparse, urljoin\n\nfrom bs4 import BeautifulSoup\nimport httpx\n\n\nclass BaseClipper:\n    DOMAIN = None\n    URL_RULES = []\n    COVER_INDEX = -1\n    IMAGE_EXTS = {'webp', 'jpg', 'jpeg'}\n    IMAGE_FOLDER = ''\n    \n    def __init__(self, url, output_dir, is_download_images=True):\n        self.url = url\n        self.domain = self.DOMAIN or urlparse(self.url).netloc.replace(\"www.\", \"\").split(\".\")[0]\n        self.tags = [f\"clippings/{self.domain}\"]\n        self.title = ''\n        self.cover = ''\n        self.images = []\n        self.content = ''\n        self.created = ''\n        self.soup = None\n        self.output_dir = os.path.join(output_dir, self.domain)\n        os.makedirs(self.output_dir, exist_ok=True)\n        self.is_download_images = is_download_images\n        if self.is_download_images:\n            os.makedirs(os.path.join(self.output_dir, self.IMAGE_FOLDER), exist_ok=True)\n    \n    @classmethod\n    def match_and_redirect(cls, url):\n        for pattern, redirect in cls.URL_RULES:\n            if re.search(pattern, url):\n                if redirect:\n                    try:\n                        url = re.sub(pattern, redirect, url)\n                    except Exception:\n                        pass\n                return url\n\n    def parse(self):\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n        }\n        resp = httpx.get(self.url, headers=headers, timeout=30.0, follow_redirects=True, verify=False)\n        resp.raise_for_status()\n        self.soup = BeautifulSoup(resp.content, \"html.parser\")\n        \n        self._parse_meta()\n        self._parse_content()\n        self._set_cover()\n        self.created = datetime.now().isoformat(timespec='seconds')\n    \n    def _parse_meta(self):\n        if meta_title := self.soup.find(\"meta\", property=\"og:title\"):\n            self.title = meta_title.get('content')\n        else:\n            self.title = self.soup.title.string\n        \n        if meta_image := self.soup.find(\"meta\", property=\"og:image\"):\n            self.cover = meta_image.get('content')\n            if self.cover and self.is_download_images:\n                self.cover = self._download_image(self.cover)\n    \n    def _parse_images(self):\n        images = []\n        seen = set()\n        \n        for url in self._parse_image():\n            img_url = self._normalize(url)\n            if self._filter_image(img_url) and img_url not in seen:\n                seen.add(img_url)\n                images.append(self._download_image(img_url) if self.is_download_images else img_url)\n        return images\n\n    def _parse_image(self):\n        for img in self.soup.select('img'):\n            if src := img.get('src'):\n                yield src\n\n    def _normalize(self, url):\n        if url.startswith(\"//\"):\n            return \"https:\" + url\n        elif url.startswith((\"http://\", \"https://\", \"data:\")):\n            return url\n        return urljoin(self.url, url)\n\n    def _filter_image(self, img_url):\n        if not self.IMAGE_EXTS:\n            return True\n\n        if img_url.startswith(\"data:image/\"):\n            ext = img_url.split(';')[0].split('/')[1]\n        else:\n            ext = img_url.split('?')[0].split('#')[0].split('.')[-1].lower()\n        \n        return ext in self.IMAGE_EXTS\n\n    def _download_image(self, url):\n        try:\n            if url.startswith(\"data:image/\"):\n                header, data = url.split(\",\", 1)\n                img_data = base64.b64decode(data)\n                ext = header.split(';')[0].split('/')[1]\n            else:\n                resp = httpx.get(url, timeout=30)\n                resp.raise_for_status()\n                img_data = resp.content\n                ext = url.split('?')[0].split('#')[0].split('.')[-1].lower()\n            \n            filename = f\"{hashlib.md5(img_data).hexdigest()}.{ext}\"\n            with open(os.path.join(self.output_dir, self.IMAGE_FOLDER, filename), 'wb') as f:\n                f.write(img_data)\n            return os.path.join('.', self.IMAGE_FOLDER, filename)\n        except Exception as e:\n            print(f\"Download image failed: {url[:50]}... - {e}\")\n            return url\n\n    def _set_cover(self):\n        if not self.cover and self.images:\n            self.cover = self._get_by_index(self.images, self.COVER_INDEX)\n    \n    @staticmethod\n    def _get_by_index(arr, pos):\n        if not arr:\n            return None\n        pos = len(arr) + pos if pos < 0 else pos\n        return arr[max(0, min(pos, len(arr) - 1))]\n\n    def _parse_content(self):\n        self.images = self._parse_images()\n        self.content = \"\\n\\n\".join(f\"![]({img})\" for img in self.images)\n    \n    def generate_markdown(self):\n        cover = f'\"[[{self.cover}]]\"' if self.cover and self.cover.startswith('./') else (self.cover or '')\n\n        frontmatter = f\"\"\"---\ntitle: {self.title}\nurl: {self.url}\nimage: {cover}\ntags: {self.tags}\ncreated: {self.created}\n---\"\"\"\n        return f\"{frontmatter}\\n\\n{self.content}\"\n    \n    def save(self):\n        filepath = os.path.join(self.output_dir, self._filename() + '.md')\n        \n        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n            f.write(self.generate_markdown())\n\n    def _filename(self):\n        return re.sub(r\"[^\\w\\-]\", \"_\", self.title)[:50] if self.title else datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n\n\nclass MissavClipper(BaseClipper):\n    DOMAIN = 'missav'\n    URL_RULES = [\n        (r'https://missav\\.([a-z]+)/dm18/cn/([0-9a-z-]+)', '')\n    ]\n\n    def __init__(self, url, output_dir, is_download_images=True):\n        super().__init__(url, output_dir, is_download_images)\n        self.tags.append('av')\n\n    def _parse_image(self):\n        for element in self.soup.select(\"div.plyr__poster\"):\n            if style := element.get('style'):\n                match = re.search(r\"background-image:\\s*url\\(['\\\"]?(.*?)['\\\"]?\\)\", style)\n                if match:\n                    yield match.group(1)\n\n    def _parse_content(self):\n        pass\n\n    def _filename(self):\n        return self.domain + '-' + self.url.rstrip('/').split('?')[0].split('#')[0].split('/')[-1]\n\n\nclass PornyClipper(BaseClipper):\n    DOMAIN = '91'\n    URL_RULES = [\n        (\n            r\"https://(.*)/view_video\\.php\\?viewkey=([a-z0-9]+).*\",\n            r\"https://tog.jiuse9002.com/video/view/\\2\",\n        ),\n        (\n            r\"https://(.*)/video(s)?/view(hd)?/(.*)\",\n            r\"https://tog.jiuse9002.com/video\\2/view/\\4\",\n        ),\n    ]\n\n    def __init__(self, url, output_dir, is_download_images=True):\n        super().__init__(url, output_dir, is_download_images)\n        self.tags.append('av')\n\n    def _parse_image(self):\n        for img in self.soup.select('video'):\n            if src := img.get('poster'):\n                yield src\n\n    def _parse_content(self):\n        pass\n\n    def _filename(self):\n        return self.domain + '-' + self.url.rstrip('/').split('?')[0].split('#')[0].split('/')[-1]\n\n\nclass ChiguaClipper(BaseClipper):\n    DOMAIN = '51'\n    URL_RULES = [\n        (r\"https://(.*)/archives/(.*)\", r\"https://aide.sdovcthe.com/archives/\\2\")\n    ]\n    \n    def __init__(self, url, output_dir, is_download_images=False):\n        super().__init__(url, output_dir, is_download_images)\n        self.tags.append('av')\n\n    def _parse_image(self):\n        for img in self.soup.select('div.post-content img'):\n            if src := img.get('data-xkrkllgl'):\n                yield src\n\n    def _parse_images(self):\n        return []\n\n    def _set_cover(self):\n        self.cover = ''\n\n    def _filename(self):\n        return self.domain + '-' + self.url.rstrip('/').split('?')[0].split('#')[0].split('/')[-1]\n\n\nclass WebToMarkdown:\n    CLIPPERS = [PornyClipper, ChiguaClipper]\n    \n    def __init__(self, output_dir=\"./output\"):\n        self.output_dir = output_dir\n        os.makedirs(output_dir, exist_ok=True)\n    \n    def get_clipper(self, url):\n        for clipper_class in self.CLIPPERS:\n            if new_url := clipper_class.match_and_redirect(url):\n                print(f\"\\n{clipper_class.__name__}  {new_url}\")\n                return clipper_class(new_url, self.output_dir)\n        return BaseClipper(url, self.output_dir)\n    \n    def process_url(self, url):\n        try:\n            clipper = self.get_clipper(url)\n            clipper.parse()\n            clipper.save()\n        except Exception as e:\n            print(f\"ERROR {url}: {e}\")\n            print(traceback.format_exc())\n    \n    def process_urls(self, urls):\n        if isinstance(urls, str):\n            urls = urls.strip().split()\n        for url in urls:\n            self.process_url(url)\n\n\nif __name__ == \"__main__\":\n    converter = WebToMarkdown()\n    converter.process_urls([\n        'https://tog.jiuse9005.com/video/view/1126684461',\n        'https://chair.ydftqji.xyz/archives/158228',\n        'https://missav.live/dm18/cn/fc2-ppv-1157625'\n    ])\n    converter.process_urls(\"\"\"\n\n\"\"\")\n"})})]})}function f(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);